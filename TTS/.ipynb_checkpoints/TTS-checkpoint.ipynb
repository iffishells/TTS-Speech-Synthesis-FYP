{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad93bbc-7dff-4e59-876c-8d804e24cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import pprint \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import numpy as np\n",
    "\n",
    "# import time\n",
    "import time\n",
    "\n",
    "\n",
    "# selenium servies\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91f91e74-55bf-45e9-9696-7dee0f59a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linguistic:\n",
    "    def __init__(self,filePath):\n",
    "        self.filePath = filePath\n",
    "    \n",
    "    def IPA(self,token_list):\n",
    "        filledIPA = []\n",
    "        for token in token_list:\n",
    "            IPAString = \"\"\n",
    "            for char in token:\n",
    "                # print(\"Char : \",char)\n",
    "                # print(\"type : \",type(char))\n",
    "                ret = self.df_ipa(char)\n",
    "                # print(ret)\n",
    "                \n",
    "                print(\"Token : {} ,char : {} , IPA : {} \".format(token,char,ret))\n",
    "                IPAString = IPAString+str(ret)\n",
    "            filledIPA.append(IPAString)\n",
    "            \n",
    "        # print('filledIPA : ',filledIPA)\n",
    "        return filledIPA\n",
    "            \n",
    "        \n",
    "    def df_ipa(self,TokenChar):\n",
    "        '''\n",
    "            There are three type dictonary Final, medial and initial and \n",
    "        '''\n",
    "        df = pd.read_csv(\"Datasets/IPA_pashto.csv\",encoding=\"utf-8\")\n",
    "        \n",
    "        array_isolated = np.array(df['Isolated'])\n",
    "        array_Final = np.array(df['Final'])\n",
    "        array_Medial = np.array(df['Medial'])\n",
    "        array_Initial = np.array(df['Initial'])\n",
    "        \n",
    "        # general array combined with everyone\n",
    "        IPA = np.array(df['IPA'])\n",
    "        \n",
    "        \n",
    "        # dict1 for isolated\n",
    "        Isolated_dict = {}\n",
    "        Final_dict = {}\n",
    "        Medial_dict = {}\n",
    "        Initial_dict = {}\n",
    "        try :\n",
    "            \n",
    "            if len(array_isolated) == len(IPA) and  len(array_Final) == len(IPA) and len(array_Medial) == len(IPA) and len(array_Initial) == len(IPA):\n",
    "\n",
    "                for index in range(0,len(IPA)):\n",
    "                    # for isolated dictionary\n",
    "                    Isolated_dict[ array_isolated[index].strip(' ')   ] = IPA[index].strip('')\n",
    "\n",
    "                    # for Final dictionary \n",
    "                    Final_dict[array_Final[index].strip(' ')] = IPA[index].strip(' ')\n",
    "\n",
    "                    # for middle dictionary \n",
    "                    Medial_dict[array_Medial[index].strip(' ')] = IPA[index].strip(' ')\n",
    "\n",
    "                    # for initial dictionary\n",
    "                    Initial_dict[array_Initial[index].strip(' ')] = IPA[index].strip(' ')\n",
    "\n",
    "                    # for\n",
    "\n",
    "\n",
    "                # print(\"Isolated Dict : \",Isolated_dict)\n",
    "                # print(\"Final Dict : \",Final_dict)\n",
    "                # print(\"Medial Dict : \",Medial_dict)\n",
    "                # print(\"Initial Dict : \",Initial_dict)\n",
    "        except:\n",
    "            print(\"Key value must be equal in df_ipa function \")\n",
    "        # print(\"Given char \",TokenChar)\n",
    "        # print(\"return char : \",Initial_dict[TokenChar])\n",
    "        # print(\"key \",Isolated_dict.keys())\n",
    "        # print(\"value\",Isolated_dict.values())\n",
    "        \n",
    "        \n",
    "        if TokenChar in Initial_dict:\n",
    "            if Initial_dict[TokenChar] != None:\n",
    "                # print(\"init cond\")\n",
    "                return Initial_dict[TokenChar]\n",
    "            \n",
    "        elif TokenChar in Final_dict:\n",
    "            if Final_dict[TokenChar] != None:\n",
    "                # print(\"Final cond\")\n",
    "                return Final_dict[TokenChar]\n",
    "        elif TokenChar in Medial_dict:\n",
    "            if Medial_dict[TokenChar] != None:\n",
    "                # print(\"Medial cond\")\n",
    "                return Medial_dict[TokenChar]\n",
    "                \n",
    "        elif TokenChar in Isolated_dict:\n",
    "            if Isolated_dict[TokenChar]!= None:\n",
    "                # print(\"Isoalted cond\")\n",
    "                return Isolated_dict[TokenChar]\n",
    "        else:\n",
    "            with open('NotavailableIPA.txt' , 'w') as file:\n",
    "                print('wrote in file')\n",
    "                file.write(TokenChar)\n",
    "                Isolated_dict[TokenChar] = 'r'\n",
    "            return Isolated_dict[TokenChar]\n",
    "\n",
    "        \n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    # pass\n",
    "    obl = linguistic('/NotavailableIPA.txt')\n",
    "    # obl.IPA(['څرګندونې', 'د', 'افغانستان', 'لپاره', 'د', 'مرستو', 'ټولولو', 'کنفرانس', 'ته', 'په', 'خبرو', 'کې', 'کولې', 'د', 'افغانستان', 'لپاره', 'د', 'نړیوالو', 'مرستو', 'د', 'راټولولو', 'په', 'موخه', 'دا', 'نړیواله', 'غونډه', 'جينېوا', 'کې', 'جوړه', 'شوې', 'ده', 'د', 'ملګرو', 'ملتونو', 'سرمنشي', 'زیاتوي', 'د', 'ملګرو', 'ملتونو', 'د', 'غوښتل', 'شویو', 'څلور', 'عشاریه', 'څلور', 'ميلیارد', 'ډالرو', 'یوازې', '۱۳', 'سلنه', 'پيسې', 'تر', 'لاسه', 'شوې', 'دي', 'ښاغلي', 'ګوتېرېش', 'پر', 'طالبانو', 'نېوکه', 'وکړه', 'چې', 'نجونې', 'یې', 'له', 'شپږمو', 'ټولګیو', 'پورته', 'له', 'زدکړو', 'را', 'ګرځولې', 'دي', 'خو', 'ټینګار', 'یې', 'دا', 'و', 'چې', 'نړې', 'دې', 'افغانستان', 'له', 'پامه', 'نه', 'غورځوي', 'ملګري', 'ملتونه', 'وايي', 'د', 'افغانستان', '۹۵', 'سلنه', 'خلک', 'کافي', 'خواړه', 'نه', 'لري', 'او', 'نړیوالو', 'بنسټونه', 'د', 'دغه', 'هېواد', 'بشري', 'حالت', 'ناورین', 'بللی', 'دی', 'بریتانیا', 'افغانستان', 'کې', 'د', 'بشري\\u200c', 'ناورین', 'مخنیوي', 'لپاره', 'مرستې', 'وغوښتې', 'ملګري', 'ملتونه', 'د', 'بشري', 'مرستو', 'ځنډېدل', 'به', 'افغانستان', 'کې', 'ستونزې', 'لا', 'ډېرې', 'کړي', 'د', 'افغانستان', 'بشري', 'کړکېچ؛', 'لسګونه', 'ماشومان', 'له', 'شري', 'او', 'خوارځواکۍ', 'مړه', 'شوي'])\n",
    "    # print(obl.df_ipa('ﺭ'))\n",
    "    # print(type('ﺭ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801c1dae-d1ae-48ee-bbfd-7b7fd45c2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreProcessing:\n",
    "    \n",
    "    def __init__(self,OrginalText):\n",
    "        self.OrginalText = OrginalText\n",
    "        # print(\"Orginal Text :{} \".format(self.OrginalText))\n",
    "        \n",
    "        \n",
    "    def Cleaning(self,Sentance):\n",
    "        \n",
    "        # case 0 : remove extra space if exist \n",
    "        # RES = Removed Extra spaceed\n",
    "        RES = Sentance.strip()\n",
    "        \n",
    "        \n",
    "        # case 2 : remove English character if exist :\n",
    "        # REC  = Removed English Character\n",
    "        REC = re.sub('[a-zA-Z]' ,\"\",RES)\n",
    "        \n",
    "        # case 3 :  Remove special character:\n",
    "        # RSC = Removed Special characters\n",
    "        RSC = re.sub( '[~!@#$%^&*()-_+]' , \"\",REC )\n",
    "        \n",
    "        # console print \n",
    "        # print(\"Cleaned Text : {} \".format(RSC))\n",
    "        \n",
    "        return RSC\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def Tokenization(self,Sentance):\n",
    "        # case 1 [Tokenization] from Python lib's\n",
    "        \n",
    "        \n",
    "        TokenizedText = word_tokenize(Sentance)\n",
    "        \n",
    "        # print(\"Tokenized Text : {}\".format(TokenizedText))\n",
    "        \n",
    "        return TokenizedText\n",
    "    \n",
    "    \n",
    "    def Normalization(sefl,sentance):\n",
    "        \n",
    "        # case 3 [Replace Counting digit to Pashto couting words]\n",
    "        \n",
    "        MathDigit = ['1','2','3','4','5','6','7','8','9','0']\n",
    "        \n",
    "        # iterate over all Math digit and replace with it\n",
    "        pasto_counting_dict = {\n",
    "           '1': \"يو\",\n",
    "             '2': \"دؤه\",\n",
    "             '3':\"درے\",\n",
    "             '4':\"څلور\",\n",
    "             '5':\"پنځه\",\n",
    "             '6':\"شپږ\",\n",
    "             '7':\"أوؤه\",\n",
    "             '8':\"أته\",\n",
    "             '9':\"نهه\",\n",
    "             '0' : \"صفر\"\n",
    "        }\n",
    "        \n",
    "        \n",
    "        for digit in MathDigit:\n",
    "            sentance = sentance.replace(digit ,pasto_counting_dict[digit] )\n",
    "        # print(\"Normalized Text : {}\".format(sentance))\n",
    "        \n",
    "        return sentance\n",
    "    def Testing(self,Text):\n",
    "        \n",
    "        # case 1 clean it \n",
    "        CleanedText = self.Cleaning(Text)\n",
    "        \n",
    "        # case 2 : Normalization\n",
    "        NormalaizedText = self.Normalization(CleanedText)\n",
    "        \n",
    "        # case 3 Tokenization\n",
    "        \n",
    "        TokenizedText = self.Tokenization(NormalaizedText)\n",
    "        \n",
    "        # print(\"Final Text : \",TokenizedText)\n",
    "        \n",
    "        self.IPA(TokenizedText)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "    \n",
    "\n",
    "    \n",
    "# randomINput = \"عقل ګودرغاړهاولاړشو غاړه  افلاكو علم انشاء علم\"\n",
    "# ProObject = TextPreProcessing(randomINput)\n",
    "# ProObject.Testing(ProObject.OrginalText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc336c5f-2a12-4e4d-8ec6-623e975a25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTS(TextPreProcessing ,linguistic):\n",
    "    def __init__(self,text):\n",
    "        TextPreProcessing.__init__(self,text)\n",
    "        self.vowels = ['ɑ' ,'ā','ə','i','e','ai','əi']\n",
    "        \n",
    "        self.consonant = ['b','p' ,'t̪','ʈ','s','d͡ʒ','t͡ʃ','h' , 'd','x','t͡s','d͡z' ,'d̪' ,'ɖ','z','r','ɻ','z','d͡z','ʐ','s','ʃ','x','s','d̪' ,'t̪','z','ɣ','f','q','k','ɡ','l','m','n','ɳ','w','h','t']\n",
    "        \n",
    "        # Avaible syllble form that we can generate voice using this\n",
    "        self.validated_Syllble = ['V','VC','VCC','CV','CVC','CVCC','CCV','CCVC','CCVCC','CCCV' , 'CCCVC' , 'CCCVCC']\n",
    "        \n",
    "\n",
    "        \n",
    "        ## dictionary for making the stats of single form of CV\n",
    "        self.dt = {\n",
    "            'consonant': ['b','p' ,'t̪','ʈ','s','d͡ʒ','t͡ʃ','h' , 'd','x','t͡s','d͡z' ,'d̪' ,'ɖ','z','r','ɻ','z','d͡z','ʐ','s','ʃ','x','s','d̪' ,'t̪','z','ɣ','f','q','k','ɡ','l','m','n','ɳ','w','h','t'],\n",
    "             'ɑ' :  np.zeros(len(self.consonant)), \n",
    "            'ā' :   np.zeros(len(self.consonant)),\n",
    "             'ə' :   np.zeros(len(self.consonant)),\n",
    "            'i':  np.zeros(len(self.consonant)),\n",
    "            'e' :    np.zeros(len(self.consonant)),\n",
    "            'ai':   np.zeros(len(self.consonant)),\n",
    "            'əi':  np.zeros(len(self.consonant))\n",
    "                    }\n",
    "        self.single_form = pd.DataFrame.from_dict(self.dt).set_index('consonant')\n",
    "        \n",
    "    def Make_Syllables(self,list_of_IPAs):\n",
    "        # print(list_of_IPAs)\n",
    "        sylb_list = []\n",
    "\n",
    "        for outer_counter , outer_index in enumerate(range(0,len(list_of_IPAs))):\n",
    "\n",
    "            # pick the Single IPA\n",
    "\n",
    "            sylb_form = ''\n",
    "            for char_counter , char_index in enumerate(range(0,len(list_of_IPAs[outer_index]))):\n",
    "\n",
    "                # now you have single char IPA\n",
    "                # print('char Counter {} and char {}'.format(char_counter ,list_of_IPAs[outer_index][char_index]))\n",
    "\n",
    "                # case 1 check the given char is consonent ?\n",
    "\n",
    "                # test : d̪\n",
    "\n",
    "                if list_of_IPAs[outer_index][char_index] in self.consonant:\n",
    "                    # print(\"yes its a consonent\" , list_of_IPAs[outer_index][char_index])\n",
    "\n",
    "                    # case 1.1 check the next char(Multiple syllables)\n",
    "                    try :\n",
    "\n",
    "                        if list_of_IPAs[outer_index][char_index+1] == '͡' or list_of_IPAs[outer_index][char_index+1] == '̪':\n",
    "                            # print(\"meet 1 cond \", list_of_IPAs[outer_index][char_index+1])\n",
    "                            sylb_form += \"C\"\n",
    "                        else:\n",
    "                            # print(\"meet 2 cond\")\n",
    "                            sylb_form += \"C\"\n",
    "                    except:\n",
    "                        if list_of_IPAs[outer_index][char_index] in self.consonant:\n",
    "                            # print(\"meet 3 cond\")\n",
    "                            sylb_form += \"C\"\n",
    "                        elif list_of_IPAs[outer_index][char_index] in self.vowels:\n",
    "                            # print(\"meet 4 cond\") \n",
    "                            sylb_form += \"V\"\n",
    "\n",
    "\n",
    "                elif list_of_IPAs[outer_index][char_index] in self.vowels:\n",
    "                    # print(\"yes its a vowels\")\n",
    "                    sylb_form += \"V\"\n",
    "                else:\n",
    "                    # for space\n",
    "                    if list_of_IPAs[outer_index][char_index] == ' ':\n",
    "                        sylb_form += \" \"\n",
    "                    continue\n",
    "            sylb_list.append(sylb_form)\n",
    "            # print('sylb_form : ',sylb_form)\n",
    "        # print(sylb_list)            \n",
    "        # print(list_of_IPAs)\n",
    "        \n",
    "        return sylb_list ,list_of_IPAs  \n",
    "    \n",
    "            \n",
    "    def Testing(self,Text):\n",
    "        \n",
    "        # case 1 clean it \n",
    "        CleanedText = self.Cleaning(Text)\n",
    "        \n",
    "        # case 2 : Normalization\n",
    "        NormalaizedText = self.Normalization(CleanedText)\n",
    "        \n",
    "        # case 3 Tokenization\n",
    "        \n",
    "        TokenizedText = self.Tokenization(NormalaizedText)\n",
    "        \n",
    "        # print(\"Final Text : \",TokenizedText)\n",
    "        \n",
    "        # print(self.IPA(TokenizedText))\n",
    "        \n",
    "        syllbleForm ,list_of_IPA =  self.Make_Syllables(self.IPA(TokenizedText))\n",
    "        \n",
    "        self.ValidationOfSyllables( syllbleForm ,list_of_IPA )\n",
    "        \n",
    "    def ValidationOfSyllables(self,syllbleForm , list_of_IPA):\n",
    "        # This function validated the syllable form of list of ipa\n",
    "        # for example PH ->> CC (this is not valid IPA)\n",
    "        \n",
    "        # print('Syllable form {}\\n List of IPA : {} '.format(syllbleForm , list_of_IPA))\n",
    "        contr =0\n",
    "        for form in range(0 , len(syllbleForm)):\n",
    "            \n",
    "            # if given pattern is validated then skip it otherwise make syllables\n",
    "            # if syllbleForm[form] in self.validated_Syllble:\n",
    "            self.Stats(list_of_IPA[form])\n",
    "            # if contr >5:\n",
    "                # break\n",
    "                # self.request_to_read_IPA(list_of_IPA[form])\n",
    "                # time.sleep(5)\n",
    "            # else:\n",
    "                # pass\n",
    "            \n",
    "        print(self.single_form)\n",
    "        self.single_form.to_csv('singleForm.csv')\n",
    "                \n",
    "                \n",
    "                        \n",
    "    def Stats(self,IPA):\n",
    "        # print('integrated IPA : ',IPA)\n",
    "        #check the df\n",
    "#         print(self.single_form.head(5))\n",
    "        \n",
    "        # print('Type(IPA) : {}\\n IPA : {}'.format(type(IPA),IPA))\n",
    "        \n",
    "         # ['ɑ' ,'ā','ə','i','e','ai','əi']\n",
    "        for count ,char_id in enumerate(range(0,len(IPA))):\n",
    "            print('Count {} --> Char {} , IPA : {} IPA[-1] : {}'.format(count,IPA[char_id],IPA,IPA[-1]))\n",
    "\n",
    "            # check each if this then increament in df\n",
    "            for cons in self.consonant:\n",
    "\n",
    "                if (IPA[char_id] == cons and IPA[char_id] != IPA[-1]) and IPA[char_id +1] =='ɑ'  :\n",
    "\n",
    "                    # print('meet -0  and self.single_form.loc[cons][0] '.format( cons,self.single_form.loc[cons,'ɑ']))\n",
    "                    self.single_form.loc[cons,'ɑ'] = self.single_form.loc[cons,'ɑ'] +1\n",
    "                    print( \"loc -->\\n\",self.single_form.loc[cons,'ɑ'])\n",
    "\n",
    "\n",
    "                if (IPA[char_id] == cons and IPA[char_id] != IPA[-1]) and IPA[char_id +1] =='ā' :\n",
    "\n",
    "                    print('meet -01 ' ,cons)\n",
    "                    self.single_form.loc[cons,'ā'] = self.single_form.loc[cons,'ā'] +1\n",
    "                    print( \"loc -->\",self.single_form.loc[cons,'ā'])\n",
    "\n",
    "                if (IPA[char_id] == cons and   IPA[char_id] != IPA[-1]) and IPA[char_id +1] =='ə' :\n",
    "\n",
    "                    print('meet -02' ,cons)\n",
    "                    self.single_form.loc[cons,'ə'] = self.single_form.loc[cons,'ə'] +1\n",
    "                    print( \"loc -->\",self.single_form.loc[cons ,'ə'])\n",
    "                if (IPA[char_id] == cons and  IPA[char_id] != IPA[-1]) and IPA[char_id +1] =='i' :\n",
    "\n",
    "                    print('meet -03' ,cons)\n",
    "                    self.single_form.loc[cons,'i'] = self.single_form.loc[cons,'i'] +1\n",
    "                    print( \"loc -->\",self.single_form.loc[cons,'i'])\n",
    "                if (IPA[char_id] == cons and  IPA[char_id] != IPA[-1]) and IPA[char_id +1] =='e':\n",
    "\n",
    "                    print('meet -04' ,cons)\n",
    "                    self.single_form.loc[cons,'e'] = self.single_form.loc[cons,'e'] +1\n",
    "                    print( \"loc -->\",self.single_form.loc[cons,'e'])\n",
    "                if (IPA[char_id] == cons and IPA[char_id] != IPA[-1]) and IPA[char_id +1] =='ai':\n",
    "\n",
    "                    print('meet -05' ,cons)\n",
    "                    self.single_form.loc[cons,'ai'] =  self.single_form.loc[cons,'ai'] +1\n",
    "                    print( \"loc -->\",self.single_form.loc[cons,'ai'])\n",
    "\n",
    "                if (IPA[char_id] == cons and IPA[char_id] != IPA[-1]) and IPA[char_id +1] =='əi' :\n",
    "\n",
    "                    print('meet -06' ,cons)\n",
    "                    self.single_form.loc[cons,'ai'] = self.single_form.loc[cons,'ai'] +1\n",
    "                    print( \"loc -->\",self.single_form.loc[cons,'ai'])\n",
    "\n",
    "\n",
    "            print(self.single_form)\n",
    "\n",
    "    \n",
    "    def request_to_read_IPA(self,ipa):\n",
    "\n",
    "\n",
    "        #  getting input tags\n",
    "        input_ipa = driver.find_element('id','ipa-text')\n",
    "        \n",
    "        input_ipa.clear()\n",
    "        # sennding IPA\n",
    "        input_ipa.send_keys(ipa)\n",
    "\n",
    "        # getting read button\n",
    "        read_button = driver.find_element('id','submit')\n",
    "        \n",
    "        read_button.click()\n",
    "        \n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85259241-d57a-4b28-97e3-ec6116d4b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "# getting request\n",
    "# driver.get('http://ipa-reader.xyz/') \n",
    "\n",
    "\n",
    "with open('UserInput.txt','r') as file:\n",
    "    RawInput = file.read()\n",
    "    \n",
    "# print(str(RawInput))\n",
    "Object =  TTS(RawInput)\n",
    "Object.Testing(RawInput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
